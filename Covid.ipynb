{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4288f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import cwt,ricker\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler,normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.layers import Flatten,concatenate,Layer,Dense,LSTM,Activation,MaxPooling2D,Dropout,Conv2D,BatchNormalization,Reshape,UpSampling2D,ZeroPadding2D\n",
    "#import nibabel as nib\n",
    "#import pydicom as dicom\n",
    "#from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "#import tensorflow_io as tfio\n",
    "import radiomics\n",
    "from radiomics.featureextractor import RadiomicsFeatureExtractor\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2e0a6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b711c6aa",
   "metadata": {},
   "source": [
    "Section how I extract the real features from the dataset and save them as arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ebd050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF_ENABLE_ONEDNN_OPTS=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e59cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = './covid19/kcv/'\n",
    "\n",
    "# Function takes a list of folders, extract features from it, change the extractor inside function and the return dictionary\n",
    "# to run exactly which feature, the key of the return dictionary can be found in mask.ipy and also listed in pyradiomics library\n",
    "def LoadDataFromImages(foldernames):\n",
    "    input_array = []\n",
    "    #output_array=[]\n",
    "    o1=[]\n",
    "    o2=[]\n",
    "    o3=[]\n",
    "    o4=[]\n",
    "    o5=[]\n",
    "\n",
    "    extractor = RadiomicsFeatureExtractor()\n",
    "    # Disable all classes except firstorder\n",
    "    extractor.disableAllFeatures()\n",
    "    extractor.enableFeaturesByName(firstorder=['Skewness'])  # change here to extract\n",
    "    extractor.enableFeaturesByName(glcm=['Autocorrelation'])\n",
    "    extractor.enableFeaturesByName(glrlm=['GrayLevelVariance','RunLengthNonUniformity'])\n",
    "    extractor.enableFeaturesByName(glszm=['SizeZoneNonUniformity'])\n",
    "\n",
    "    for i in foldernames:\n",
    "        files  = sorted(os.listdir(dict + i))\n",
    "        for j in files:\n",
    "            im = sitk.ReadImage(dict + i +'/' + j)\n",
    "            \n",
    "            # reshape and fill the input array\n",
    "            input_array.append(sitk.GetArrayFromImage(im).reshape(512,512,1))\n",
    "            \n",
    "            ma_arr = np.ones(im.GetSize()[::-1])  # reverse the order as image is xyz, array is zyx\n",
    "            ma = sitk.GetImageFromArray(ma_arr)\n",
    "            ma.CopyInformation(im)  # Copy geometric info\n",
    "            \n",
    "            # extract features and fill the output array\n",
    "            features = extractor.execute(im, ma)\n",
    "            \n",
    "            #output_array.append(features['original_ngtdm_Strength'])  # change here to extract\n",
    "            o1.append(features['original_firstorder_Skewness'])\n",
    "            o2.append(features['original_glcm_Autocorrelation'])\n",
    "            o3.append(features['original_glrlm_GrayLevelVariance'])\n",
    "            o4.append(features['original_glrlm_RunLengthNonUniformity'])\n",
    "            o5.append(features['original_glszm_SizeZoneNonUniformity'])\n",
    "\n",
    "            \n",
    "    return input_array,o1,o2,o3,o4,o5\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array, o1,o2,o3,o4,o5 = LoadDataFromImages([\"pos\", \"neg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfc91e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.array(input_array)\n",
    "o1 = np.array(o1)\n",
    "o2 = np.array(o2)\n",
    "o3 = np.array(o3)\n",
    "o4 = np.array(o4)\n",
    "o5 = np.array(o5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a44ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"input_arr.npy\",input_array)\n",
    "np.save(\"o1ar.npy\",o1)\n",
    "np.save(\"o2ar.npy\",o2)\n",
    "np.save(\"o3ar.npy\",o3)\n",
    "np.save(\"o4ar.npy\",o4)\n",
    "np.save(\"o5ar.npy\",o5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ba61e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"input_arr_test.npy\",input_array)\n",
    "# np.save(\"o1ar_test.npy\",o1)\n",
    "# np.save(\"o2ar_test.npy\",o2)\n",
    "# np.save(\"o3ar_test.npy\",o3)\n",
    "# np.save(\"o4ar_test.npy\",o4)\n",
    "# np.save(\"o5ar_test.npy\",o5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "37c6ae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save(\"input_arr_finet.npy\",input_array)\n",
    "# np.save(\"o1ar_finet.npy\",o1)\n",
    "# np.save(\"o2ar_finet.npy\",o2)\n",
    "# np.save(\"o3ar_finet.npy\",o3)\n",
    "# np.save(\"o4ar_finet.npy\",o4)\n",
    "# np.save(\"o5ar_finet.npy\",o5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496d37a",
   "metadata": {},
   "source": [
    "# Load the Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d27e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# label index 0 is positive, 1 is negative\n",
    "class_names = ['pos', 'neg']\n",
    "dict = './covid19/kcv/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7695eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_training():\n",
    "    trainingdata = []\n",
    "    for i in class_names:\n",
    "        path = os.path.join(dict, i)\n",
    "        label_num = class_names.index(i)\n",
    "        for j in sorted(os.listdir(path)):\n",
    "            img = sitk.ReadImage(dict + i +'/' + j)\n",
    "            trainingdata.append([sitk.GetArrayFromImage(img).reshape(512,512,1),label_num])\n",
    "            \n",
    "    return trainingdata\n",
    "    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b54d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= load_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88855fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "425f84e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =[]\n",
    "Y =[]\n",
    "\n",
    "for trainingx, label in data:\n",
    " \n",
    "    X.append(trainingx)\n",
    "    Y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83b7010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load input images and output features:\n",
    "#data = np.load('input_arr.npy')\n",
    "\n",
    "feature_arr1 = np.load('o1ar.npy')  # original_firstorder_Skewness\n",
    "feature_arr2 = np.load('o2ar.npy')  # original_glcm_Autocorrelation\n",
    "feature_arr3 = np.load('o3ar.npy')  # original_glrlm_GrayLevelVariance\n",
    "feature_arr4 = np.load('o4ar.npy')  # original_glrlm_RunLengthNonUniformity\n",
    "feature_arr5 = np.load('o5ar.npy')  # original_glszm_SizeZoneNonUniformity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fc39e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply k fold cross validation, k=10\n",
    "kfold = KFold(10,shuffle=True,random_state=1)\n",
    "\n",
    "traingroup = []\n",
    "testgroup=[]\n",
    "\n",
    "feature1_train= []\n",
    "feature2_train= []\n",
    "feature3_train= []\n",
    "feature4_train= []\n",
    "feature5_train= []\n",
    "\n",
    "feature1_test= []\n",
    "feature2_test= []\n",
    "feature3_test= []\n",
    "feature4_test= []\n",
    "feature5_test= []\n",
    "\n",
    "output_label_train = []\n",
    "output_label_test = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# split data to 10 train and test set\n",
    "for train, test in kfold.split(X):\n",
    "    #print('train: %s, test: %s' % (train, test))\n",
    "    per_train_group = []\n",
    "    per_test_group=[]\n",
    "    \n",
    "    per_feature1_train = []\n",
    "    per_feature2_train = []\n",
    "    per_feature3_train = []\n",
    "    per_feature4_train = []\n",
    "    per_feature5_train = []\n",
    "    \n",
    "    per_feature1_test = []\n",
    "    per_feature2_test = []\n",
    "    per_feature3_test = []\n",
    "    per_feature4_test = []\n",
    "    per_feature5_test = []\n",
    "    \n",
    "    per_label_train =[]\n",
    "    per_label_test = []\n",
    "    \n",
    "    for i in train:\n",
    "        per_train_group.append(X[i])\n",
    "        per_label_train.append(Y[i])\n",
    "        per_feature1_train.append(feature_arr1[i])\n",
    "        per_feature2_train.append(feature_arr2[i])\n",
    "        per_feature3_train.append(feature_arr3[i])\n",
    "        per_feature4_train.append(feature_arr4[i])\n",
    "        per_feature5_train.append(feature_arr5[i])\n",
    "    for i in test:\n",
    "        per_test_group.append(X[i])\n",
    "        per_label_test.append(Y[i])\n",
    "        per_feature1_test.append(feature_arr1[i])\n",
    "        per_feature2_test.append(feature_arr2[i])\n",
    "        per_feature3_test.append(feature_arr3[i])\n",
    "        per_feature4_test.append(feature_arr4[i])\n",
    "        per_feature5_test.append(feature_arr5[i])\n",
    "        \n",
    "        \n",
    "    traingroup.append(per_train_group)\n",
    "    testgroup.append(per_test_group)\n",
    "    \n",
    "    feature1_train.append(per_feature1_train)\n",
    "    feature2_train.append(per_feature2_train)\n",
    "    feature3_train.append(per_feature3_train)\n",
    "    feature4_train.append(per_feature4_train)\n",
    "    feature5_train.append(per_feature5_train)\n",
    "    \n",
    "    feature1_test.append(per_feature1_test)\n",
    "    feature2_test.append(per_feature2_test)\n",
    "    feature3_test.append(per_feature3_test)\n",
    "    feature4_test.append(per_feature4_test)\n",
    "    feature5_test.append(per_feature5_test)\n",
    "    \n",
    "    output_label_train.append(per_label_train)\n",
    "    output_label_test.append(per_label_test)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68557892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert them into numpy arrays\n",
    "traingroup = np.array(traingroup)\n",
    "testgroup= np.array(testgroup)\n",
    "\n",
    "feature1_train= np.array(feature1_train)\n",
    "feature2_train= np.array(feature2_train)\n",
    "feature3_train= np.array(feature3_train)\n",
    "feature4_train= np.array(feature4_train)\n",
    "feature5_train= np.array(feature5_train)\n",
    "\n",
    "feature1_test= np.array(feature1_test)\n",
    "feature2_test= np.array(feature2_test)\n",
    "feature3_test= np.array(feature3_test)\n",
    "feature4_test= np.array(feature4_test)\n",
    "feature5_test= np.array(feature5_test)\n",
    "\n",
    "output_label_train = np.array(output_label_train)\n",
    "output_label_test = np.array(output_label_test)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95b6725f",
   "metadata": {},
   "source": [
    "to save the data array for convinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49df4131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('t1',traingroup)\n",
    "# np.save('t2',testgroup)\n",
    "\n",
    "# np.save('t3',feature1_train)\n",
    "# np.save('t4',feature2_train)\n",
    "# np.save('t5',feature3_train)\n",
    "# np.save('t6',feature4_train)\n",
    "# np.save('t7',feature5_train)\n",
    "\n",
    "# np.save('t8',feature1_test)\n",
    "# np.save('t9',feature2_test)\n",
    "# np.save('t10',feature3_test)\n",
    "# np.save('t11',feature4_test)\n",
    "# np.save('t12',feature5_test)\n",
    "\n",
    "# np.save('t13',output_label_train)\n",
    "# np.save('t14',output_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1be9c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traingroup = np.load('t1.npy')\n",
    "# testgroup= np.load('t2.npy')\n",
    "\n",
    "# feature1_train= np.load('t3.npy')\n",
    "# feature2_train= np.load('t4.npy')\n",
    "# feature3_train= np.load('t5.npy')\n",
    "# feature4_train= np.load('t6.npy')\n",
    "# feature5_train= np.load('t7.npy')\n",
    "\n",
    "# feature1_test= np.load('t8.npy')\n",
    "# feature2_test= np.load('t9.npy')\n",
    "# feature3_test= np.load('t10.npy')\n",
    "# feature4_test= np.load('t11.npy')\n",
    "# feature5_test= np.load('t12.npy')\n",
    "\n",
    "# output_label_train = np.load('t13.npy')\n",
    "# output_label_test = np.load('t14.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "423022af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear GPU session\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df06a84",
   "metadata": {},
   "source": [
    "# Regular Neural network with Random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e89950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a simple Network\n",
    "def MakeModel(modelname):\n",
    "    input_layer = keras.Input(shape=(512,512,1))\n",
    "    x = Flatten()(input_layer)\n",
    "    #x = BatchNormalization(axis=1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "    out = Dense(2, activation = 'softmax', name= modelname)(x)\n",
    "\n",
    "    model = keras.Model(input_layer, out, name= modelname)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2efd64fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-04 16:40:19.244452: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-04 16:40:19.876422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11560 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:0a:00.0, compute capability: 3.7\n"
     ]
    }
   ],
   "source": [
    "RNNModel = MakeModel('RNNModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9c7c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RNNModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 512, 512, 1)]     0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 262144)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               33554560  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " RNNModel (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,571,201\n",
      "Trainable params: 33,571,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNNModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b997170",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNModel.compile(optimizer=tf.keras.optimizers.Adam(\n",
    " learning_rate= 0.0001\n",
    "),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy']\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a97a7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='history_rnn3.csv'\n",
    "history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "943f0873",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_rnn = RNNModel.fit(traingroup[9], output_label_train[9], \n",
    "                validation_data=([testgroup[9],output_label_test[9]]), \n",
    "                batch_size=64,\n",
    "                epochs=10,\n",
    "                          callbacks=[history_logger])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3573a80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNModel.save('rnnSample.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f6bae",
   "metadata": {},
   "source": [
    "# Simple models with raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33637b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = np.stack((feature1_train,feature2_train,feature3_train,feature4_train, feature5_train),axis=2)\n",
    "features_test = np.stack((feature1_test,feature2_test,feature3_test,feature4_test, feature5_test),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0955784d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 7200, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49b1ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def MakeModel(modelname):\n",
    "    input_layer = keras.Input(shape=(5))\n",
    "\n",
    "    \n",
    "    #x = Flatten()(n_d)\n",
    "    #x = BatchNormalization(axis=1)(x)\n",
    "    x = Dense(128, activation='relu')(input_layer)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "    out = Dense(2, activation = 'softmax', name= modelname)(x)\n",
    "\n",
    "    model = keras.Model(input_layer, out, name= modelname)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76823657",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawFeatureModel = MakeModel('rawFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75d22bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"rawFeatures\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               768       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " rawFeatures (Dense)         (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,538\n",
      "Trainable params: 17,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rawFeatureModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce05aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='history_rawfeature2.csv'\n",
    "history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f052404",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawFeatureModel.compile(optimizer=tf.keras.optimizers.Adam(\n",
    " learning_rate= 0.001\n",
    "),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy']\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b886f918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "113/113 [==============================] - 1s 4ms/step - loss: 71.1637 - accuracy: 0.8818 - val_loss: 59.5046 - val_accuracy: 0.8650\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 77.6017 - accuracy: 0.8726 - val_loss: 48.0486 - val_accuracy: 0.8900\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 35.4895 - accuracy: 0.8990 - val_loss: 39.0126 - val_accuracy: 0.8875\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 56.3496 - accuracy: 0.8846 - val_loss: 23.5839 - val_accuracy: 0.8863\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 34.3744 - accuracy: 0.9032 - val_loss: 22.6378 - val_accuracy: 0.8012\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 61.3941 - accuracy: 0.8885 - val_loss: 352.5455 - val_accuracy: 0.8587\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 58.3414 - accuracy: 0.8847 - val_loss: 40.9347 - val_accuracy: 0.8938\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 47.8116 - accuracy: 0.8953 - val_loss: 30.3586 - val_accuracy: 0.8988\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 17.4297 - accuracy: 0.9056 - val_loss: 175.5617 - val_accuracy: 0.8587\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 0s 2ms/step - loss: 47.8875 - accuracy: 0.8904 - val_loss: 30.2605 - val_accuracy: 0.8925\n"
     ]
    }
   ],
   "source": [
    "history_rawFeature= rawFeatureModel.fit(features_train[9], output_label_train[9], \n",
    "                validation_data=([features_test[9],output_label_test[9]]), \n",
    "                batch_size=64,\n",
    "                epochs=10,\n",
    "                                       callbacks=[history_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89d0b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawFeatureModel.save('RawFeature.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738b8c32",
   "metadata": {},
   "source": [
    "# FINs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f9da32e",
   "metadata": {},
   "source": [
    "Fine-Tune witth images, load the real extracted features from fine-tune dataset, and fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "cd9799f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.load('input_arr_finet.npy')\n",
    "output_array = np.load('o1ar_finet.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a7035eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model =  load_model(\"radiomics_Skewness.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ea0c3522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Skewness\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 512, 512, 1)]     0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 262144)            0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 262144)           1048576   \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                16777280  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " Skewness (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,842,561\n",
      "Trainable params: 17,318,273\n",
      "Non-trainable params: 524,288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "12d0ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many layers for saving\n",
    "newlayers = base_model.layers[6].output\n",
    "n1 = Dense(64, activation='relu',name = '1')(newlayers)\n",
    "out = Dense(1, activation='linear',name='2')(n1)\n",
    "new_model = keras.Model(base_model.input, outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "681dea38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 512, 512, 1)]     0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 262144)            0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 262144)           1048576   \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                16777280  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " 1 (Dense)                   (None, 64)                4160      \n",
      "                                                                 \n",
      " 2 (Dense)                   (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,842,561\n",
      "Trainable params: 17,318,273\n",
      "Non-trainable params: 524,288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "457f7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(base_model.layers)): \n",
    "    keras.layers.trainable = True   # True--> fine tine, False-->frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "7c08be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    " learning_rate= 0.00001\n",
    "), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6a56cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 35ms/step - loss: 0.0875\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.1135\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.0765\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0544\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0716\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0537\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0689\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0619\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0545\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0469\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0386\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0482\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0462\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0331\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0572\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0633\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0447\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0627\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0478\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0590\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0645\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0514\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0462\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0479\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0435\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0449\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0525\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0423\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0563\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0387\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0393\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0409\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0537\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0392\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0329\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0381\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0370\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0589\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0472\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0527\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0396\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0710\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0635\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0503\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0453\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0324\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0450\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0637\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0803\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0494\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0414\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0549\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0350\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0677\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0336\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0366\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0321\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0394\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0355\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0341\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0387\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0385\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0376\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0592\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0294\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0333\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0344\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0330\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0524\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0362\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0317\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0415\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0379\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0463\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0543\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0283\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.0338\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0514\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0337\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0357\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0336\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0426\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0396\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0363\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0443\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0347\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0233\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0384\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0289\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0278\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0409\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0379\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0480\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.1114\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0393\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0423\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0443\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0302\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.0301\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.0466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b00ebc5e700>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(input_array, output_array, \n",
    "              epochs=100, \n",
    "          batch_size=64,\n",
    "                shuffle=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1c00a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.save(\"./finetune_Skewness.h5\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "01859365",
   "metadata": {},
   "source": [
    "Training Fins Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39d0c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the model using the Fins\n",
    "\n",
    "# loading FINs\n",
    "m1 = load_model('finetune_Skewness.h5')\n",
    "m2 = load_model('finetune_Autocorrelation.h5')\n",
    "m3 = load_model('finetune_GrayLevelVariance.h5')\n",
    "m4 = load_model('finetune_RunLengthNonUniformity.h5')\n",
    "m5 = load_model('finetune_SizeZoneNonUniformity.h5')\n",
    "\n",
    "\n",
    "def MakeModel(modelname):\n",
    "    input_layer = keras.Input(shape=(512,512,1))\n",
    "    \n",
    "    l1 = m1(input_layer)\n",
    "    l2 = m2(input_layer)\n",
    "    l3 = m3(input_layer)\n",
    "    l4 = m4(input_layer)\n",
    "    l5 = m5(input_layer)\n",
    "    \n",
    "    n_d = concatenate([l1,l2\n",
    "                       ,l4,l3,l5\n",
    "                      ])\n",
    "    \n",
    "    x = Dense(128, activation='relu',name='x1')(n_d)\n",
    "\n",
    "    x = Dense(128, activation='relu',name='x2')(x)\n",
    "\n",
    "    out = Dense(2, activation = 'softmax', name= modelname)(x)\n",
    "\n",
    "    model = keras.Model(input_layer, out, name= modelname)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a889a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinModel = MakeModel('Fin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf94aa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Fin\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 512, 512, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_15 (Functional)          (None, 1)            17842561    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " model_14 (Functional)          (None, 1)            34669313    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " model_8 (Functional)           (None, 1)            34714561    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " model_10 (Functional)          (None, 1)            9443585     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " model_6 (Functional)           (None, 1)            68486913    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 5)            0           ['model_15[0][0]',               \n",
      "                                                                  'model_14[0][0]',               \n",
      "                                                                  'model_8[0][0]',                \n",
      "                                                                  'model_10[0][0]',               \n",
      "                                                                  'model_6[0][0]']                \n",
      "                                                                                                  \n",
      " x1 (Dense)                     (None, 128)          768         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " x2 (Dense)                     (None, 128)          16512       ['x1[0][0]']                     \n",
      "                                                                                                  \n",
      " Fin (Dense)                    (None, 2)            258         ['x2[0][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 165,174,471\n",
      "Trainable params: 162,553,031\n",
      "Non-trainable params: 2,621,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "FinModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b6c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='history_fin2.csv'\n",
    "history_logger=tf.keras.callbacks.CSVLogger(filename, separator=\",\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "671f89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "FinModel.compile(optimizer=tf.keras.optimizers.Adam(\n",
    " learning_rate= 0.001\n",
    "),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy']\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f332793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "113/113 [==============================] - 8s 33ms/step - loss: 22.9553 - accuracy: 0.8694 - val_loss: 0.3500 - val_accuracy: 0.9262\n",
      "Epoch 2/10\n",
      "113/113 [==============================] - 3s 28ms/step - loss: 0.1278 - accuracy: 0.9593 - val_loss: 0.0873 - val_accuracy: 0.9725\n",
      "Epoch 3/10\n",
      "113/113 [==============================] - 3s 28ms/step - loss: 0.0562 - accuracy: 0.9832 - val_loss: 0.0930 - val_accuracy: 0.9688\n",
      "Epoch 4/10\n",
      "113/113 [==============================] - 3s 27ms/step - loss: 0.0478 - accuracy: 0.9867 - val_loss: 0.0405 - val_accuracy: 0.9837\n",
      "Epoch 5/10\n",
      "113/113 [==============================] - 3s 28ms/step - loss: 0.0305 - accuracy: 0.9903 - val_loss: 0.0672 - val_accuracy: 0.9737\n",
      "Epoch 6/10\n",
      "113/113 [==============================] - 3s 28ms/step - loss: 0.0549 - accuracy: 0.9862 - val_loss: 0.0399 - val_accuracy: 0.9887\n",
      "Epoch 7/10\n",
      "113/113 [==============================] - 3s 27ms/step - loss: 0.5569 - accuracy: 0.9444 - val_loss: 0.0566 - val_accuracy: 0.9862\n",
      "Epoch 8/10\n",
      "113/113 [==============================] - 3s 27ms/step - loss: 0.0424 - accuracy: 0.9910 - val_loss: 0.0555 - val_accuracy: 0.9800\n",
      "Epoch 9/10\n",
      "113/113 [==============================] - 3s 27ms/step - loss: 0.0327 - accuracy: 0.9939 - val_loss: 0.0421 - val_accuracy: 0.9837\n",
      "Epoch 10/10\n",
      "113/113 [==============================] - 3s 28ms/step - loss: 0.0196 - accuracy: 0.9957 - val_loss: 0.0258 - val_accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "history_fin = FinModel.fit(traingroup[9], output_label_train[9], \n",
    "                validation_data=([testgroup[9],output_label_test[9]]), \n",
    "                batch_size=64,\n",
    "                epochs=10, callbacks=[history_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69e81cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_df = pd.DataFrame(history_fin.history) \n",
    "# hist_csv_file = 'history_fin.csv'\n",
    "# with open(hist_csv_file, mode='w') as f:\n",
    "#     hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "628b03a9",
   "metadata": {},
   "source": [
    "testing the performance of Fin for a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "809f27c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.6536526e-05, 9.9994349e-01]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the folder name by label\n",
    "class_names = ['pos','neg']\n",
    "\n",
    "# the image dictionary we are loading\n",
    "dict = './covid19/kcv/'\n",
    "\n",
    "def load_image( imageName ):\n",
    "    trainingdata = []\n",
    "    for i in class_names:\n",
    "        path = os.path.join(dict, i)\n",
    "        label_num = class_names.index(i)\n",
    "        try:\n",
    "            img = sitk.ReadImage(dict + i +'/' + imageName)\n",
    "            trainingdata.append([sitk.GetArrayFromImage(img).reshape(512,512,1),label_num])\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    return trainingdata\n",
    "\n",
    "singleImage = load_image('Non-COVID-19_042.png')\n",
    "\n",
    "image = singleImage[0][0]\n",
    "label = singleImage[0][1]\n",
    "image = np.array(image)\n",
    "inputimage = image.reshape(1,512,512,1)\n",
    "\n",
    "FinModel.predict(inputimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec91950d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}